{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d2c977",
   "metadata": {},
   "source": [
    "# Save Video Based on Events\n",
    "The following code should take a video and every 8 seconds save the first event that occurs in the form of a video. However, it is not properly saving the video currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae0b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def process_and_save(vid_path, output_dir):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    frame_size = (frame_width, frame_height)\n",
    "    \n",
    "    print(\"FPS: \" + str(fps) + \"\\n Frame Size:\")\n",
    "    print(frame_size)\n",
    "    \n",
    "    \n",
    "    # Create Background Subtractor MOG2 object\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "    \n",
    "    # Initialize variables for event detection\n",
    "    event_detected = False\n",
    "    event_start_time = 0\n",
    "    event_counter = 1\n",
    "#     print(\"test1\")\n",
    "#     print(cap.isOpened())\n",
    "    count = 0\n",
    "    \n",
    "    # Initialize buffer for frames before the event\n",
    "    buffer_frames = []\n",
    "    buffer_size = 45  # Number of frames to keep in the buffer\n",
    "    \n",
    "    new_frame_size = (int(frame_width)-int(frame_width/3), int(frame_height-frame_height/12)-int(frame_height/2))\n",
    "    \n",
    "    \n",
    "    # Process each frame\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        #print(\"TEST\" + str(event_counter))\n",
    "        if ret:\n",
    "            \n",
    "            # Convert frame to grayscale\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Crop the frame to a desired area\n",
    "#             frame = frame[int(frame_height/2):int(frame_height-frame_height/12),int(frame_width/3):int(frame_width)]\n",
    "            \n",
    "            \n",
    "            # Apply background subtraction\n",
    "            fg_mask = backSub.apply(frame)\n",
    "            \n",
    "            # Apply thresholding to remove shadows\n",
    "            retval, mask_thresh = cv2.threshold(fg_mask, 254, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # Apply morphological operations (erosion)\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "            mask_eroded = cv2.morphologyEx(mask_thresh, cv2.MORPH_OPEN, kernel)\n",
    "            \n",
    "            # Find contours\n",
    "            contours, hierarchy = cv2.findContours(mask_eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # Define minimum contour area threshold\n",
    "            min_contour_area = 400\n",
    "            \n",
    "            # Filter contours based on area\n",
    "            large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\n",
    "            \n",
    "            # Create a copy of the frame\n",
    "            frame_out = frame.copy()\n",
    "            \n",
    "            # Event detection and processing\n",
    "            if large_contours and not event_detected:\n",
    "                # If motion is detected and no event is currently detected\n",
    "                event_detected = True\n",
    "                event_start_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                print(\"Event detected at:\", event_start_time)\n",
    "                \n",
    "                # Create output directory if it doesn't exist\n",
    "                if not os.path.exists(output_dir):\n",
    "                    os.makedirs(output_dir)\n",
    "                \n",
    "                # Construct output video filename\n",
    "                output_video = os.path.join(output_dir, \"RangeImpact{}.mp4\".format(event_counter))\n",
    "                \n",
    "                #New frame size\n",
    "                \n",
    "                # Create a new output video file with correct code\n",
    "                out = cv2.VideoWriter(, cv2.VideoWriter_fourcc(*\"XVID\"), fps, frame_size)\n",
    "                event_counter += 1\n",
    "                \n",
    "                #Save frames from the buffer before the event\n",
    "                for buffer_frame in buffer_frames:\n",
    "                    out.write(buffer_frame)\n",
    "                \n",
    "                # Clear the buffer\n",
    "                buffer_frames = []\n",
    "            \n",
    "            if event_detected:\n",
    "                # If an event is detected\n",
    "                elapsed_time = cap.get(cv2.CAP_PROP_POS_MSEC) - event_start_time\n",
    "                \n",
    "                if elapsed_time <= 3000:  # Up to 3 seconds after the event\n",
    "                    # If within the desired time range, save the frame\n",
    "                    if out is not None:\n",
    "                        out.write(frame)\n",
    "                        #cv2.imshow(\"Frame_with_Contours\", frame)\n",
    "                        \n",
    "                elif elapsed_time >= 8000:\n",
    "                    # If 8 seconds total has passed\n",
    "                    event_detected = False\n",
    "                    if out is not None:\n",
    "                        out.release()\n",
    "                else:\n",
    "                    if out is not None:\n",
    "                        out.release()\n",
    "            else:\n",
    "                # If no event is detected, add frame to the buffer\n",
    "                buffer_frames.append(frame_out.copy())\n",
    "                # Keep the buffer size limited\n",
    "                if len(buffer_frames) > buffer_size:\n",
    "                    buffer_frames.pop(0)\n",
    "            \n",
    "            # Display the processed frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            \n",
    "            # Check for user input to quit\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Release video capture\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"released\")\n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
